{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用設備: cuda\n",
      "從頭開始訓練模型，資料來源設為 archive_3。\n",
      "掃描圖片資料夾: ./archive_3\n",
      "找到 113062 張符合條件的圖片。\n",
      "資料集划分: 訓練集 90449，驗證集 11306，測試集 11307\n",
      "資料已保存為: ./data\\train_data_original.pt, ./data\\valid_data_original.pt, ./data\\test_data_original.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ray03\\AppData\\Local\\Temp\\ipykernel_47716\\3397734042.py:639: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(train_path)\n",
      "C:\\Users\\ray03\\AppData\\Local\\Temp\\ipykernel_47716\\3397734042.py:640: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_data = torch.load(valid_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從頭開始訓練模型。\n",
      "Epoch [1/50]\n",
      "train loss: 3.8346, train accu: 0.00%\n",
      "val loss: 3.6462, val accu: 0.00%\n",
      "驗證準確率未提升，耐心計數器: 1/6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 739\u001b[0m\n\u001b[0;32m    736\u001b[0m         sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 739\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[3], line 683\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    680\u001b[0m     save_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_SAVE_DIR, model_save_filename)\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;66;03m# 訓練模型\u001b[39;00m\n\u001b[1;32m--> 683\u001b[0m     train_model(\n\u001b[0;32m    684\u001b[0m         train_loader,\n\u001b[0;32m    685\u001b[0m         valid_loader,\n\u001b[0;32m    686\u001b[0m         save_model_path\u001b[38;5;241m=\u001b[39msave_model_path,\n\u001b[0;32m    687\u001b[0m         num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m    688\u001b[0m         pretrained_model_path\u001b[38;5;241m=\u001b[39mpretrained_model_path\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m模型已保存為 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m operation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# 列出所有模型文件\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 455\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_loader, valid_loader, save_model_path, num_epochs, pretrained_model_path)\u001b[0m\n\u001b[0;32m    448\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    449\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)  \u001b[38;5;66;03m# [seq_len, batch, num_classes]\u001b[39;00m\n\u001b[0;32m    451\u001b[0m input_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(\n\u001b[0;32m    452\u001b[0m     size\u001b[38;5;241m=\u001b[39m(images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),),\n\u001b[0;32m    453\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39moutputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    454\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong\n\u001b[1;32m--> 455\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    456\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels, input_lengths, label_lengths)\n\u001b[0;32m    458\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 設定隨機種子以確保結果可重現\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 定義圖片的目標大小，所有圖片將縮放到此大小\n",
    "IMAGE_SIZE = (128, 32)  # 根據驗證碼圖片調整大小\n",
    "\n",
    "# 定義圖片所在的資料夾\n",
    "IMAGE_DIR = \"./archive_3\"    # 原始圖片資料夾\n",
    "NEW_IMAGE_DIR = \"./img-new\"  # 新增圖片資料夾\n",
    "\n",
    "# 定義資料保存的資料夾\n",
    "DATA_SAVE_DIR = \"./data\"    # 所有 .pt 文件和模型將保存於此\n",
    "\n",
    "# 定義字母數字列表\n",
    "ALPHA_NUMS = \"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "NUM_CLASSES = len(ALPHA_NUMS) + 1  # 加1是為了CTC的blank字符\n",
    "\n",
    "# 定義驗證碼的位數範圍\n",
    "MIN_DIGITS = 4\n",
    "MAX_DIGITS = 6\n",
    "\n",
    "# 檢查設備是否有GPU可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用設備: {device}\")\n",
    "\n",
    "# 建立字符與索引的映射\n",
    "char_to_idx = {c: i + 1 for i, c in enumerate(ALPHA_NUMS)}  # 從1開始，0留給blank\n",
    "idx_to_char = {i + 1: c for i, c in enumerate(ALPHA_NUMS)}\n",
    "idx_to_char[0] = ''  # blank字符\n",
    "\n",
    "def image_to_tensor(img):\n",
    "    \"\"\"\n",
    "    將圖片轉換為Tensor\n",
    "    :param img: PIL Image物件\n",
    "    :return: 經過處理的Tensor\n",
    "    \"\"\"\n",
    "    in_img = img.resize(IMAGE_SIZE)\n",
    "    in_img = in_img.convert(\"L\")  # 轉換為灰階圖\n",
    "    arr = np.array(in_img)\n",
    "    t = torch.from_numpy(arr).float()\n",
    "    t = t.unsqueeze(0)  # 增加通道維度\n",
    "    t = t / 255.0  # 進行歸一化\n",
    "    return t\n",
    "\n",
    "def code_to_indices(code):\n",
    "    \"\"\"\n",
    "    將驗證碼字串轉換為索引列表\n",
    "    :param code: 驗證碼字串\n",
    "    :return: 索引列表\n",
    "    \"\"\"\n",
    "    return [char_to_idx[c] for c in code.lower() if c in char_to_idx]\n",
    "\n",
    "def prepare_data(image_dir, save_prefix):\n",
    "    \"\"\"\n",
    "    準備訓練資料\n",
    "    :param image_dir: 圖片所在的資料夾\n",
    "    :param save_prefix: 保存資料的前綴（例如 'new'）\n",
    "    :return: (train_path, valid_path, test_path) 或 None\n",
    "    \"\"\"\n",
    "    # 創建保存資料的資料夾\n",
    "    if not os.path.isdir(DATA_SAVE_DIR):\n",
    "        os.makedirs(DATA_SAVE_DIR)\n",
    "        print(f\"建立資料保存資料夾: {DATA_SAVE_DIR}\")\n",
    "\n",
    "    print(f\"掃描圖片資料夾: {image_dir}\")\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(image_dir):\n",
    "        for filename in files:\n",
    "            if not (filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\")):\n",
    "                continue\n",
    "            path = os.path.join(root, filename)\n",
    "            code = filename.split(\".\")[0]\n",
    "            if MIN_DIGITS <= len(code) <= MAX_DIGITS:\n",
    "                if all(c in ALPHA_NUMS for c in code.lower()):\n",
    "                    image_paths.append(path)\n",
    "                    labels.append(code)\n",
    "                else:\n",
    "                    print(f\"跳過包含無效字符的檔案: {filename}\")\n",
    "\n",
    "    print(f\"找到 {len(image_paths)} 張符合條件的圖片。\")\n",
    "\n",
    "    # 檢查是否有資料\n",
    "    if len(image_paths) == 0:\n",
    "        print(\"未找到符合條件的圖片。請檢查圖片資料夾和命名格式。\")\n",
    "        return None\n",
    "\n",
    "    # 打亂資料\n",
    "    data = list(zip(image_paths, labels))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # 划分資料集\n",
    "    total_samples = len(data)\n",
    "    train_size = int(0.8 * total_samples)\n",
    "    valid_size = int(0.1 * total_samples)\n",
    "    test_size = total_samples - train_size - valid_size\n",
    "\n",
    "    train_data = data[:train_size]\n",
    "    valid_data = data[train_size:train_size + valid_size]\n",
    "    test_data = data[train_size + valid_size:]\n",
    "\n",
    "    print(f\"資料集划分: 訓練集 {len(train_data)}，驗證集 {len(valid_data)}，測試集 {len(test_data)}\")\n",
    "\n",
    "    # 保存資料\n",
    "    train_path = os.path.join(DATA_SAVE_DIR, f\"train_data_{save_prefix}.pt\")\n",
    "    valid_path = os.path.join(DATA_SAVE_DIR, f\"valid_data_{save_prefix}.pt\")\n",
    "    test_path = os.path.join(DATA_SAVE_DIR, f\"test_data_{save_prefix}.pt\")\n",
    "\n",
    "    torch.save(train_data, train_path)\n",
    "    torch.save(valid_data, valid_path)\n",
    "    torch.save(test_data, test_path)\n",
    "\n",
    "    print(f\"資料已保存為: {train_path}, {valid_path}, {test_path}\")\n",
    "    return train_path, valid_path, test_path\n",
    "\n",
    "class CaptchaDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    驗證碼資料集\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, code = self.data[idx]\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                image = image_to_tensor(img)\n",
    "        except Exception as e:\n",
    "            print(f\"無法打開圖片 {path}: {e}\")\n",
    "            # 跳過這個樣本，重新隨機選擇一個樣本\n",
    "            return self.__getitem__(random.randint(0, len(self.data) - 1))\n",
    "        label = code_to_indices(code)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    用於DataLoader的collate_fn，處理不同長度的序列\n",
    "    :param batch: 一批資料\n",
    "    :return: 圖片Tensor，標籤Tensor，標籤長度Tensor\n",
    "    \"\"\"\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "\n",
    "    label_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
    "    labels = torch.cat(labels)\n",
    "\n",
    "    return images, labels, label_lengths\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN + LSTM 模型\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 第一個卷積區塊\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # 第二個卷積區塊\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # 第三個卷積區塊\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 第四個卷積區塊\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),\n",
    "\n",
    "            # 第五個卷積區塊\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 第六個卷積區塊\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),\n",
    "\n",
    "            # 第七個卷積區塊\n",
    "            nn.Conv2d(512, 512, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # 輸出高度現在為1\n",
    "        )\n",
    "\n",
    "        # 定義LSTM和全連接層\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=512,\n",
    "            hidden_size=256,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cnn(x)  # [batch, channels, height, width]\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"卷積輸出的高度必須為1\"\n",
    "        conv = conv.squeeze(2)  # [batch, channels, width]\n",
    "        conv = conv.permute(0, 2, 1)  # [batch, width, channels]\n",
    "\n",
    "        recurrent, _ = self.lstm(conv)\n",
    "        output = self.fc(recurrent)\n",
    "        output = output.permute(1, 0, 2)  # [width, batch, num_classes]\n",
    "        return output  # CTC Loss需要輸入形狀為 (seq_len, batch_size, num_classes)\n",
    "\n",
    "def decode_predictions(preds):\n",
    "    \"\"\"\n",
    "    將模型預測的輸出轉換為字串\n",
    "    :param preds: 模型預測結果\n",
    "    :return: 預測的字串列表\n",
    "    \"\"\"\n",
    "    preds = preds.permute(1, 0, 2)  # [batch, seq_len, num_classes]\n",
    "    preds = torch.argmax(preds, dim=2)  # [batch, seq_len]\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    decoded_strings = []\n",
    "    for pred in preds:\n",
    "        chars = []\n",
    "        prev_char_idx = None\n",
    "        for idx in pred:\n",
    "            if idx != prev_char_idx and idx != 0:\n",
    "                chars.append(idx_to_char.get(idx, ''))\n",
    "            prev_char_idx = idx\n",
    "        decoded_strings.append(''.join(chars))\n",
    "    return decoded_strings\n",
    "\n",
    "def calculate_accuracy(model, data_loader):\n",
    "    \"\"\"\n",
    "    計算模型在資料集上的準確率\n",
    "    :param model: 訓練好的模型\n",
    "    :param data_loader: 資料加載器\n",
    "    :return: 準確率\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, label_lengths in data_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)  # [seq_len, batch, num_classes]\n",
    "            outputs = outputs.log_softmax(2)\n",
    "            preds = outputs.detach().cpu()\n",
    "            pred_strings = decode_predictions(preds)\n",
    "\n",
    "            labels = labels.cpu().numpy()\n",
    "            label_lengths = label_lengths.cpu().numpy()\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            total_count += batch_size\n",
    "\n",
    "            label_strings = []\n",
    "            index = 0\n",
    "            for length in label_lengths:\n",
    "                label = labels[index:index + length]\n",
    "                label_str = ''.join([idx_to_char.get(idx, '') for idx in label])\n",
    "                label_strings.append(label_str)\n",
    "                index += length\n",
    "\n",
    "            for pred_str, label_str in zip(pred_strings, label_strings):\n",
    "                if pred_str == label_str:\n",
    "                    correct_count += 1\n",
    "\n",
    "    accuracy = correct_count / total_count\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_model(save_model_path, test_data_path):\n",
    "    \"\"\"\n",
    "    評估模型並生成混淆矩陣\n",
    "    :param save_model_path: 模型檔案路徑\n",
    "    :param test_data_path: 測試資料集路徑\n",
    "    \"\"\"\n",
    "    # 載入測試資料\n",
    "    if not os.path.exists(test_data_path):\n",
    "        print(f\"測試資料檔案 '{test_data_path}' 不存在。請先準備資料。\")\n",
    "        return\n",
    "\n",
    "    test_data = torch.load(test_data_path)\n",
    "    test_dataset = CaptchaDataset(test_data)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # 載入模型\n",
    "    model = CRNN(num_classes=NUM_CLASSES).to(device)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(save_model_path, map_location=device))\n",
    "        print(f\"已載入模型: {save_model_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"模型檔案 '{save_model_path}' 未找到。請先訓練模型。\")\n",
    "        return\n",
    "    model.eval()\n",
    "\n",
    "    total_sequences = 0  # 總序列數\n",
    "    correct_sequences = 0  # 完全正確的序列數\n",
    "\n",
    "    total_chars = 0  # 總字符數\n",
    "    correct_chars = 0  # 正確字符數\n",
    "\n",
    "    all_true_chars = []\n",
    "    all_pred_chars = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, label_lengths in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)  # [seq_len, batch, num_classes]\n",
    "            outputs = outputs.log_softmax(2)\n",
    "            preds = outputs.detach().cpu()\n",
    "            pred_strings = decode_predictions(preds)\n",
    "\n",
    "            labels = labels.cpu().numpy()\n",
    "            label_lengths = label_lengths.cpu().numpy()\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            total_sequences += batch_size  # 增加序列計數\n",
    "\n",
    "            label_strings = []\n",
    "            index = 0\n",
    "            for length in label_lengths:\n",
    "                label = labels[index:index + length]\n",
    "                label_str = ''.join([idx_to_char.get(idx, '') for idx in label])\n",
    "                label_strings.append(label_str)\n",
    "                total_chars += length  # 增加字符計數\n",
    "                index += length\n",
    "\n",
    "            for pred_str, label_str in zip(pred_strings, label_strings):\n",
    "                if pred_str == label_str:\n",
    "                    correct_sequences += 1  # 完全正確的序列計數\n",
    "\n",
    "                # 逐字符比較，計算字符準確率\n",
    "                min_len = min(len(pred_str), len(label_str))\n",
    "                for i in range(min_len):\n",
    "                    if pred_str[i] == label_str[i]:\n",
    "                        correct_chars += 1  # 增加正確字符計數\n",
    "                    all_true_chars.append(label_str[i])\n",
    "                    all_pred_chars.append(pred_str[i])\n",
    "\n",
    "    # 計算準確率\n",
    "    char_accuracy = correct_chars / total_chars if total_chars > 0 else 0\n",
    "    seq_accuracy = correct_sequences / total_sequences if total_sequences > 0 else 0\n",
    "\n",
    "    print(f\"字符級準確率: {char_accuracy * 100:.2f}% (正確: {correct_chars}/{total_chars})\")\n",
    "    print(f\"序列級準確率: {seq_accuracy * 100:.2f}% (正確: {correct_sequences}/{total_sequences})\")\n",
    "\n",
    "    # 生成混淆矩陣並轉換為百分比\n",
    "    cm = confusion_matrix(all_true_chars, all_pred_chars, labels=list(ALPHA_NUMS))\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100  # 將每行轉換為百分比\n",
    "\n",
    "    # 繪製混淆矩陣\n",
    "    plt.figure(figsize=(20, 14))  # 增大圖形大小\n",
    "    sns.heatmap(\n",
    "        cm_percentage,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='Blues',\n",
    "        xticklabels=list(ALPHA_NUMS),\n",
    "        yticklabels=list(ALPHA_NUMS),\n",
    "        annot_kws={\"size\": 6},  # 調整註釋字體大小\n",
    "        cbar_kws={\"shrink\": 0.8}  # 縮小顏色條\n",
    "    )\n",
    "    plt.xlabel('Predicted Characters ', fontsize=16)  # 增大字體\n",
    "    plt.ylabel('True Characters', fontsize=16)\n",
    "    plt.title('confusion matrix(pecentage)', fontsize=18)\n",
    "    plt.xticks(fontsize=14, rotation=0)  # 旋轉x軸標籤並調整字體大小\n",
    "    plt.yticks(fontsize=14, rotation=0)   # 旋轉y軸標籤並調整字體大小\n",
    "    plt.tight_layout()\n",
    "    cm_filename = os.path.join(DATA_SAVE_DIR, f\"confusion_matrix_percentage_{os.path.splitext(os.path.basename(save_model_path))[0]}.png\")\n",
    "    plt.show()\n",
    "    print(f\"混淆矩陣已保存為 {cm_filename}\")\n",
    "\n",
    "def train_model(train_loader, valid_loader, save_model_path, num_epochs=50, pretrained_model_path=None):\n",
    "    \"\"\"\n",
    "    通用訓練函數\n",
    "    :param train_loader: 訓練資料加載器\n",
    "    :param valid_loader: 驗證資料加載器\n",
    "    :param save_model_path: 模型保存路徑\n",
    "    :param num_epochs: 訓練輪數\n",
    "    :param pretrained_model_path: 預訓練模型路徑（可選）\n",
    "    \"\"\"\n",
    "    # 建立模型\n",
    "    model = CRNN(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "    # 如果提供了預訓練模型路徑，且檔案存在，則載入模型權重\n",
    "    if pretrained_model_path and os.path.exists(pretrained_model_path):\n",
    "        model.load_state_dict(torch.load(pretrained_model_path, map_location=device))\n",
    "        print(f\"載入預訓練模型: {pretrained_model_path}\")\n",
    "    else:\n",
    "        print(\"從頭開始訓練模型。\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=1e-9)\n",
    "    criterion = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
    "\n",
    "    best_valid_accuracy = 0.0  # 初始最佳驗證準確率\n",
    "    patience = 6  # Early Stopping的耐心值，即容忍多少個epoch沒有提升\n",
    "    patience_counter = 0  # 記錄驗證準確率沒有改善的epoch次數\n",
    "\n",
    "    # 記錄損失和準確率\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "\n",
    "    # 打開CSV檔案以寫入模式\n",
    "    csv_filename = os.path.join(DATA_SAVE_DIR, f'train_val_results_{os.path.splitext(os.path.basename(save_model_path))[0]}.csv')\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        # 寫入表頭\n",
    "        csvwriter.writerow(['Epoch', 'train loss', 'val loss', 'train accu', 'val accu'])\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for images, labels, label_lengths in train_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)  # [seq_len, batch, num_classes]\n",
    "\n",
    "                input_lengths = torch.full(\n",
    "                    size=(images.size(0),),\n",
    "                    fill_value=outputs.size(0),\n",
    "                    dtype=torch.long\n",
    "                ).to(device)\n",
    "                loss = criterion(outputs, labels, input_lengths, label_lengths)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "            # 計算訓練集準確率\n",
    "            train_accuracy = calculate_accuracy(model, train_loader)\n",
    "            # 計算驗證集損失和準確率\n",
    "            model.eval()\n",
    "            total_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels, label_lengths in valid_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    input_lengths = torch.full(\n",
    "                        size=(images.size(0),),\n",
    "                        fill_value=outputs.size(0),\n",
    "                        dtype=torch.long\n",
    "                    ).to(device)\n",
    "                    loss = criterion(outputs, labels, input_lengths, label_lengths)\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "            avg_valid_loss = total_loss / len(valid_loader)\n",
    "            valid_accuracy = calculate_accuracy(model, valid_loader)\n",
    "\n",
    "            # 記錄每個epoch的損失和準確率\n",
    "            train_losses.append(avg_train_loss)\n",
    "            valid_losses.append(avg_valid_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            valid_accuracies.append(valid_accuracy)\n",
    "\n",
    "            # 將結果寫入CSV檔案\n",
    "            csvwriter.writerow([epoch, avg_train_loss, avg_valid_loss, train_accuracy, valid_accuracy])\n",
    "\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "            print(f\"train loss: {avg_train_loss:.4f}, train accu: {train_accuracy * 100:.2f}%\")\n",
    "            print(f\"val loss: {avg_valid_loss:.4f}, val accu: {valid_accuracy * 100:.2f}%\")\n",
    "            scheduler.step(avg_valid_loss)\n",
    "\n",
    "            # Early Stopping檢查（基於驗證集準確率）\n",
    "            if valid_accuracy > best_valid_accuracy:\n",
    "                best_valid_accuracy = valid_accuracy\n",
    "                patience_counter = 0  # 重置耐心計數器\n",
    "                # 確保保存目錄存在\n",
    "                os.makedirs(os.path.dirname(save_model_path), exist_ok=True)\n",
    "                torch.save(model.state_dict(), save_model_path)\n",
    "                print(\"驗證準確率提升，模型已保存。\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"驗證準確率未提升，耐心計數器: {patience_counter}/{patience}\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(\"因為驗證準確率長期未提升，提前停止訓練。\")\n",
    "                break  # 提前停止訓練\n",
    "\n",
    "    # 繪製訓練和驗證的損失曲線\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # 準確率曲線\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(train_accuracies) + 1), [acc * 100 for acc in train_accuracies], label='train accu', color='green')\n",
    "    plt.plot(range(1, len(valid_accuracies) + 1), [acc * 100 for acc in valid_accuracies], label='val accu', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('tain and val accu')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 損失曲線\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='train loss', color='blue')\n",
    "    plt.plot(range(1, len(valid_losses) + 1), valid_losses, label='val loss', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('train and val loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 顯示圖像\n",
    "    plt.show()\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    使用訓練好的模型對單張圖片進行預測\n",
    "    \"\"\"\n",
    "    # 可用的模型列表\n",
    "    # 將所有crnn_model*.pt文件視為模型文件\n",
    "    available_models = [f for f in os.listdir(DATA_SAVE_DIR) if f.startswith(\"crnn_model\") and f.endswith(\".pt\")]\n",
    "    available_models = [os.path.join(DATA_SAVE_DIR, model) for model in available_models]\n",
    "\n",
    "    if not available_models:\n",
    "        print(\"沒有可用的模型。請先訓練模型。\")\n",
    "        return\n",
    "\n",
    "    # 顯示可用的模型\n",
    "    print(\"可用的模型:\")\n",
    "    for idx, path in enumerate(available_models, 1):\n",
    "        print(f\"{idx}. {path}\")\n",
    "    try:\n",
    "        model_choice = int(input(f\"請選擇要使用的模型編號（1-{len(available_models)}）： \").strip()) - 1\n",
    "        if model_choice < 0 or model_choice >= len(available_models):\n",
    "            raise ValueError\n",
    "        selected_model_path = available_models[model_choice]\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"無效的選擇。\")\n",
    "        return\n",
    "\n",
    "    # 載入模型\n",
    "    model = CRNN(num_classes=NUM_CLASSES).to(device)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(selected_model_path, map_location=device))\n",
    "        print(f\"已載入模型: {selected_model_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"模型檔案 '{selected_model_path}' 未找到。\")\n",
    "        return\n",
    "    model.eval()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # 輸入圖片路徑\n",
    "            image_path = input(\"請輸入圖片路徑（或按 Enter 退出）： \").strip()\n",
    "            if not image_path:\n",
    "                print(\"退出預測模式。\")\n",
    "                break\n",
    "            if not os.path.isfile(image_path):\n",
    "                print(f\"檔案 '{image_path}' 不存在，請重新輸入。\")\n",
    "                continue\n",
    "            with Image.open(image_path) as img:\n",
    "                tensor_in = image_to_tensor(img).to(device).unsqueeze(0)  # 增加批次維度\n",
    "\n",
    "            # 預測輸出\n",
    "            tensor_out = model(tensor_in)  # [seq_len, batch, num_classes]\n",
    "            preds = tensor_out.log_softmax(2)\n",
    "            pred_strings = decode_predictions(preds)\n",
    "\n",
    "            code = pred_strings[0]\n",
    "            print(f\"預測驗證碼: {code}\\n\")\n",
    "        except Exception as e:\n",
    "            print(\"發生錯誤:\", e)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函數，處理不同的操作模式\n",
    "    \"\"\"\n",
    "    operation = input(\"請輸入模式 (prepare|train|evaluate|predict): \").strip().lower()\n",
    "\n",
    "    if operation == \"prepare\":\n",
    "        prepare_result = prepare_data(IMAGE_DIR, \"original\")\n",
    "        if prepare_result:\n",
    "            print(\"資料準備完成。\")\n",
    "    elif operation == \"train\":\n",
    "        # 選擇是否使用預訓練模型\n",
    "        use_pretrained = input(\"是否使用預訓練模型進行訓練？ (y/n)： \").strip().lower()\n",
    "        if use_pretrained == 'y':\n",
    "            # 使用預訓練模型，資料來源為 img-new\n",
    "            data_source = \"new\"\n",
    "            image_dir = NEW_IMAGE_DIR\n",
    "            print(\"使用預訓練模型，資料來源設為 img-new。\")\n",
    "        else:\n",
    "            # 從頭訓練，資料來源為 archive_3\n",
    "            data_source = \"original\"\n",
    "            image_dir = IMAGE_DIR\n",
    "            print(\"從頭開始訓練模型，資料來源設為 archive_3。\")\n",
    "\n",
    "        # 準備資料\n",
    "        prepare_result = prepare_data(image_dir, data_source)\n",
    "        if prepare_result is None:\n",
    "            print(\"資料準備失敗，訓練終止。\")\n",
    "            return\n",
    "\n",
    "        train_path, valid_path, _ = prepare_result  # 測試集路徑在訓練中不需要\n",
    "\n",
    "        # 創建資料集和資料加載器\n",
    "        train_data = torch.load(train_path)\n",
    "        valid_data = torch.load(valid_path)\n",
    "\n",
    "        train_dataset = CaptchaDataset(train_data)\n",
    "        valid_dataset = CaptchaDataset(valid_data)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn\n",
    "        )\n",
    "        valid_loader = torch.utils.data.DataLoader(\n",
    "            valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        # 如果使用預訓練模型，選擇模型文件\n",
    "        if use_pretrained == 'y':\n",
    "            # 列出所有模型文件\n",
    "            model_files = [f for f in os.listdir(DATA_SAVE_DIR) if f.startswith(\"crnn_model\") and f.endswith(\".pt\")]\n",
    "            if not model_files:\n",
    "                print(\"沒有找到任何預訓練模型文件。請先訓練模型。\")\n",
    "                return\n",
    "            # 顯示可用的模型\n",
    "            print(\"可用的預訓練模型:\")\n",
    "            for idx, file in enumerate(model_files, 1):\n",
    "                print(f\"{idx}. {file}\")\n",
    "            try:\n",
    "                model_choice = int(input(f\"請選擇要載入的預訓練模型編號（1-{len(model_files)}）： \").strip()) - 1\n",
    "                if model_choice < 0 or model_choice >= len(model_files):\n",
    "                    raise ValueError\n",
    "                selected_model_file = model_files[model_choice]\n",
    "                pretrained_model_path = os.path.join(DATA_SAVE_DIR, selected_model_file)\n",
    "            except (ValueError, IndexError):\n",
    "                print(\"無效的選擇。\")\n",
    "                return\n",
    "        else:\n",
    "            pretrained_model_path = None\n",
    "\n",
    "        # 定義模型保存路徑\n",
    "        if data_source == \"original\":\n",
    "            model_save_filename = \"crnn_model_original.pt\"\n",
    "        else:\n",
    "            model_save_filename = \"crnn_model_new.pt\"\n",
    "        save_model_path = os.path.join(DATA_SAVE_DIR, model_save_filename)\n",
    "\n",
    "        # 訓練模型\n",
    "        train_model(\n",
    "            train_loader,\n",
    "            valid_loader,\n",
    "            save_model_path=save_model_path,\n",
    "            num_epochs=50,\n",
    "            pretrained_model_path=pretrained_model_path\n",
    "        )\n",
    "        print(f\"模型已保存為 '{save_model_path}'\")\n",
    "    elif operation == \"evaluate\":\n",
    "        # 列出所有模型文件\n",
    "        model_files = [f for f in os.listdir(DATA_SAVE_DIR) if f.startswith(\"crnn_model\") and f.endswith(\".pt\")]\n",
    "        if not model_files:\n",
    "            print(\"沒有找到任何模型文件。請先訓練模型。\")\n",
    "            return\n",
    "        # 顯示可用的模型\n",
    "        print(\"可用的模型:\")\n",
    "        for idx, file in enumerate(model_files, 1):\n",
    "            print(f\"{idx}. {file}\")\n",
    "        try:\n",
    "            model_choice = int(input(f\"請選擇要使用的模型編號（1-{len(model_files)}）： \").strip()) - 1\n",
    "            if model_choice < 0 or model_choice >= len(model_files):\n",
    "                raise ValueError\n",
    "            selected_model_file = model_files[model_choice]\n",
    "            selected_model_path = os.path.join(DATA_SAVE_DIR, selected_model_file)\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"無效的選擇。\")\n",
    "            return\n",
    "\n",
    "        # 列出所有 test_data*.pt 文件，包括 test_data.pt\n",
    "        test_data_files = [f for f in os.listdir(DATA_SAVE_DIR) if f.startswith(\"test_data\") and f.endswith(\".pt\")]\n",
    "        if not test_data_files:\n",
    "            print(\"沒有找到 test_data*.pt 檔案。請先準備資料。\")\n",
    "            return\n",
    "\n",
    "        # 顯示可用的測試資料集\n",
    "        print(\"可用的測試資料集:\")\n",
    "        for idx, file in enumerate(test_data_files, 1):\n",
    "            print(f\"{idx}. {file}\")\n",
    "        try:\n",
    "            test_choice = int(input(f\"請選擇要使用的測試資料集編號（1-{len(test_data_files)}）： \").strip()) - 1\n",
    "            if test_choice < 0 or test_choice >= len(test_data_files):\n",
    "                raise ValueError\n",
    "            selected_test_data_file = test_data_files[test_choice]\n",
    "            selected_test_data_path = os.path.join(DATA_SAVE_DIR, selected_test_data_file)\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"無效的選擇。\")\n",
    "            return\n",
    "\n",
    "        evaluate_model(selected_model_path, selected_test_data_path)\n",
    "    elif operation == \"predict\":\n",
    "        predict()\n",
    "    else:\n",
    "        print(f\"不支援的操作: {operation}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
